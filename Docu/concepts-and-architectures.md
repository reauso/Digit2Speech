[⬅️ Overview](../README.md)
[⬅️ Preprocessing](./preprocessing.md)

# Concepts and architectures

We evaluated different concepts and architectures to analyze and generate audio data. The following list contains the concepts and architectures we tried.

- Siren (trained on raw signal, ouputs raw signal)
- Siren (trained on mel spectrogram, outputs mel spectrogram)

In this part of the documentation, the considered network architectures are presented and further discussed.

## Siren (raw signal)<a name="siren_signal"></a>

The first concept was to use the raw signal as a base for the audio data. The Siren architecture [[3]](./references.md#papers-siren) enables to train a neural network on raw signal data (i.e. sample intensity at given times) and finally predict a signal for given a time in a signal. Additionally, a mapping layer (FilM [[2]](./references.md#papers-film)) creates an association between the data and the metadata. This association is then used in the actual Siren alongside the position (time of sample) to generate an intensity, given metadata and temporal positions. The temporal positions are positional encoded as suggested by Mildenhall et al. [[6]](./references.md#papers-nerf) to map the temporal position into a higher dimensional space which improves the reconstruction quality.

<figure>
  <img
  id="figures-siren-audio"
  src="./figures-siren-audio.png"
  alt=""
  width=400
  >
  <figcaption>Fig. 3.1: High level architecture of Siren signal generator (based on Grassal et al. [6]).</figcaption>
</figure>

[Fig. 3.2](#figures-siren-signal-process-1) shows the development of a model training from epoch 0 to 40 using the Siren Mel model. It is visible how the quality of the generated image increases from a blurry spectrogram to a more clear one.

<figure>
  <img
  id="figures-siren-signal-process-1"
  src="./2023-03-22 16-15-33_63f5f_00000.gif"
  alt="Development of a model training from epoch 0 to 40. It is visible how the quality of the generated audio signal increases.">
  <figcaption>Fig. 3.2: Development of a signal Siren training attempt of a single language (english), single gender (female), 1 Speaker and 1 digit (0) generator in 40 epochs. On the right is the ground truth signal from our validation dataset.</figcaption>
</figure>

The following table demonstrates an audio file generated by the Siren signal model. The metadata is displayed in the table header.

| model                                 | generated audio                                                             | metadata                           |
|---------------------------------------|-----------------------------------------------------------------------------|------------------------------------|
| Model trained on 1 speaker, 1 digit   | https://user-images.githubusercontent.com/46965017/227798808-764c37e9-e45d-4d7d-8603-4674e0464100.mov | female, english, digit 0, style 0  |

Table 3.1: Examples of generated audio using the raw signal siren model.

## Siren (Mel spectrogram)<a name="siren_mel"></a>

The second concept was to use the Siren architecture but with images displaying Mel spectrograms of the audio files as the base for generation. The idea is to train the model with image data for it to associate image coordinates x and y with a color value p. The model is then able to predict a color value for every coordinate of an image, resulting in a generated spectrogram. Finally, the spectrogram is then converted to a signal using the inverse Mel spectrogram transformation.
With this approach we also use the positional encoding suggested by Mildenhall et al. [[5]](./references.md#papers-nerf) but this time for the pixel coordinates.

<figure>
  <img
  id="figures-siren-mel"
  src="./figures-siren-mel.png"
  alt=""
  width=400
  >
  <figcaption>Fig. 3.3: High level architecture of Siren Mel generator (based on Grassal et al. [6])</figcaption>
</figure>

[Fig. 3.4](#figures-siren-mel-process-1) and [Fig. 3.5](#figures-siren-mel-process-2) show the development of a model training from epoch 0 to 100 using the Siren Mel model. It is visible how the quality of the generated image increases from a blurry spectrogram to a more clear one.

<figure>
  <img
  id="figures-siren-mel-process-1"
  src="./2023-03-24 18-18-41_ec594_00000.gif"
  alt="Development of a model training from epoch 0 to 100. It is visible how the quality of the generated image increases from a blurry spectrogram to a more clear one.">
  <figcaption>Fig. 3.4: Development of a mel Siren training attempt of a single language (english), single gender (female), 1 Speaker and 1 digit (0) generator in 100 epochs. On the right is the ground truth image from our validation dataset.</figcaption>
</figure>
<figure>
  <img
  id="figures-siren-mel-process-2"
  src="./2023-03-25 18-12-17_31b8f_00000.gif"
  alt="Development of a model training from epoch 0 to 100. It is visible how the quality of the generated image increases from a blurry spectrogram to a more clear one.">
  <figcaption>Fig. 3.5: Development of a mel Siren training attempt of a single language (english), single gender (female), 2 Speaker and 3 digits (0-2) generator in 100 epochs. On the right is the ground truth image from our validation dataset.</figcaption>
</figure>

The following table demonstrates some audio files generated by the Siren Mel model. The metadata is displayed in the table header. The audio files are generated using the metadata and the generated spectrogram.

| model                                 | generated audio                                                             | metadata                          |
|---------------------------------------|-----------------------------------------------------------------------------|-----------------------------------|
| Model trained on 1 speaker, 1 digit   | https://user-images.githubusercontent.com/46965017/227798594-6c729e2c-c70d-4446-a3fd-c37c59de73f7.mov | female, english, digit 0, style 0 |
| Model trained on 2 speakers, 3 digits | https://user-images.githubusercontent.com/46965017/227798714-ca6c4de8-7c79-442e-bb3a-10fb1d5c33f3.mov | female, english, digit 2, style 1 |
| Model trained on 2 speakers, 3 digits | https://user-images.githubusercontent.com/46965017/227798729-3f6017a6-fab9-48e8-9251-fc00278a8b44.mov | female, english, digit 0, style 0 |

Table 3.2: Examples of generated audio using the mel siren models.

[➡️ Development and usage](./development-and-usage.md)
