[⬅️ Overview](../README.md)
[⬅️ Future Work](./future-work.md)

# References

[1] <a name="heidelberg-dataset"></a> Benjamin Cramer, Yannik Stradmann, Johannes Schemmel, Friedemann Zenke, December 6, 2019, "Heidelberg Spiking Datasets", IEEE Dataport, doi: <https://dx.doi.org/10.21227/51gn-m114>

[2] <a name="papers-film"></a>E. Perez, F. Strub, H. de Vries, V. Dumoulin, and A. Courville, FiLM: Visual Reasoning with a General Conditioning Layer. arXiv, 2017. doi: <https://doi.org/10.48550/ARXIV.1709.07871>

[3] <a name="papers-siren"></a>V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein, Implicit Neural Representations with Periodic Activation Functions. arXiv, 2020. doi: <https://doi.org/10.48550/ARXIV.2006.09661>

[4] <a name="papers-losses"></a> H. Zhao, O. Gallo, I. Frosio and J. Kautz, "Loss Functions for Image Restoration With Neural Networks" in IEEE Transactions on Computational Imaging, vol. 3, no. 1, pp. 47-57, March 2017, doi: <https://doi.org/10.1109/TCI.2016.2644865>

[5] <a name="papers-nerf"></a> B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi, and R. Ng, NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. 2020. doi <https://doi.org/10.48550/arXiv.2003.08934>

[6] <a name="papers-neural-head-avatar"></a>P.-W. Grassal, M. Prinzler, T. Leistner, C. Rother, M. Nießner, and J. Thies, Neural Head Avatars from Monocular RGB Videos. 2022. doi: https://doi.org/10.48550/arXiv.2112.01554 

[7] <a name="papers-melgan"></a>K. Kumar et al., MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis. arXiv, 2019. doi: <https://doi.org/10.48550/ARXIV.1910.06711>

[8] <a name="papers-stylegan"></a>T. Karras, S. Laine, and T. Aila, A Style-Based Generator Architecture for Generative Adversarial Networks. 2019. doi: <https://doi.org/10.48550/arXiv.1812.04948>

[9] <a name="papers-stylegan2"></a>T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila, Analyzing and Improving the Image Quality of StyleGAN. 2020. doi: <https://doi.org/10.48550/arXiv.1912.04958>

[10] <a name="papers-p2p"></a> Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with conditional adversarial networks, 2016. doi: <https://doi.org/10.48550/arXiv.1611.07004>

[11] <a name="papers-p2phd"></a> Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans, 2017. doi: <https://doi.org/10.48550/arXiv.1711.11585>

