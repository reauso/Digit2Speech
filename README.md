# Digit2Speech

This project is an attempt to create a deep neural network which generates audio snippets of spoken digits. Primarily, it acts as a way to experiment with different neural network architectures when working with audio.

The documentation is structured into subpages further explaining the corresponding subject, which can be accessed from the table of contents.

## Table of Contents

1. [Metadata](Docs/metadata.md)
2. [Preprocessing](Docs/preprocessing.md)
3. [Dataset](Docs/dataset.md)
4. [Concepts and Architectures](Docs/concepts-and-architectures.md)
   - [Siren (raw signal)](Docs/concepts-and-architectures.md#siren_signal)
   - [Siren (mel spectrogram)](Docs/concepts-and-architectures.md#siren_mel)
   - [GAN (mel spectrogram)](Docs/concepts-and-architectures.md#gan_mel)
5. [Development and usage](Docs/development-and-usage.md)
6. [References](Docs/references.md)