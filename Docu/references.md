[⬅️ Overview](../README.md)
[⬅️ Development and usage](./development-and-usage.md)

# References

[1] <a name="heidelberg-dataset"></a> Benjamin Cramer, Yannik Stradmann, Johannes Schemmel, Friedemann Zenke, December 6, 2019, "Heidelberg Spiking Datasets", IEEE Dataport, doi: <https://dx.doi.org/10.21227/51gn-m114>

[2] <a name="papers-film"></a>E. Perez, F. Strub, H. de Vries, V. Dumoulin, and A. Courville, FiLM: Visual Reasoning with a General Conditioning Layer. arXiv, 2017. doi: <https://doi.org/10.48550/ARXIV.1709.07871>

[3] <a name="papers-siren"></a>V. Sitzmann, J. N. P. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein, Implicit Neural Representations with Periodic Activation Functions. arXiv, 2020. doi: <https://doi.org/10.48550/ARXIV.2006.09661>

[4] <a name="papers-losses"></a> H. Zhao, O. Gallo, I. Frosio and J. Kautz, "Loss Functions for Image Restoration With Neural Networks" in IEEE Transactions on Computational Imaging, vol. 3, no. 1, pp. 47-57, March 2017, doi: <https://doi.org/10.1109/TCI.2016.2644865>

[5] K. Kumar et al., MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis. arXiv, 2019. doi: <https://doi.org/10.48550/ARXIV.1910.06711>

Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with conditional adversarial networks, 2016. doi: <https://doi.org/10.48550/arXiv.1611.07004>

Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans, 2017. doi: <https://doi.org/10.48550/arXiv.1711.11585>

Karras, Tero, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen y Timo Aila: Analyzing and Improving the Image Quality of StyleGAN, 2019.
